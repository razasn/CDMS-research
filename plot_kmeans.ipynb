{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nk-means\n=======\n\nThis example uses $k$-means clustering for time series. Three variants of\nthe algorithm are available: standard\nEuclidean $k$-means, DBA-$k$-means (for DTW Barycenter Averaging)\nand Soft-DTW $k$-means.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Romain Tavenard\n# License: BSD 3 clause\n\nimport numpy\nimport matplotlib.pyplot as plt\n\nfrom tslearn.clustering import TimeSeriesKMeans\nfrom tslearn.datasets import CachedDatasets\nfrom tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n    TimeSeriesResampler\n\nseed = 0\nnumpy.random.seed(seed)\nX_train, y_train, X_test, y_test = CachedDatasets().load_dataset(\"Trace\")\nX_train = X_train[y_train < 4]  # Keep first 3 classes\nnumpy.random.shuffle(X_train)\n# Keep only 50 time series\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train[:50])\n# Make time series shorter\nX_train = TimeSeriesResampler(sz=40).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=3, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\nplt.figure()\nfor yi in range(3):\n    plt.subplot(3, 3, yi + 1)\n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")\n\n# DBA-k-means\nprint(\"DBA k-means\")\ndba_km = TimeSeriesKMeans(n_clusters=3,\n                          n_init=2,\n                          metric=\"dtw\",\n                          verbose=True,\n                          max_iter_barycenter=10,\n                          random_state=seed)\ny_pred = dba_km.fit_predict(X_train)\n\nfor yi in range(3):\n    plt.subplot(3, 3, 4 + yi)\n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    if yi == 1:\n        plt.title(\"DBA $k$-means\")\n\n# Soft-DTW-k-means\nprint(\"Soft-DTW k-means\")\nsdtw_km = TimeSeriesKMeans(n_clusters=3,\n                           metric=\"softdtw\",\n                           metric_params={\"gamma_sdtw\": .01},\n                           verbose=True,\n                           random_state=seed)\ny_pred = sdtw_km.fit_predict(X_train)\n\nfor yi in range(3):\n    plt.subplot(3, 3, 7 + yi)\n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    if yi == 1:\n        plt.title(\"Soft-DTW $k$-means\")\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}